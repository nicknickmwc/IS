{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34fc3fb7",
   "metadata": {},
   "source": [
    "# Лабораторная работа № 5\n",
    "\n",
    "## Распознавание объектов на фотографиях\n",
    "\n",
    "Задачи:\n",
    "\n",
    "   1. Ознакомиться со сверточными нейронными сетями\n",
    "   2. Изучить построение модели в Keras в функциональном виде\n",
    "   3. Изучить работу слоя разреживания (Dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e581aba",
   "metadata": {},
   "source": [
    "# Цель работы:\n",
    "Распознавание объектов на фотографиях (Object Recognition in Photographs)\n",
    "CIFAR-10 (классификация небольших изображений по десяти классам: самолет,\n",
    "автомобиль, птица, кошка, олень, собака, лягушка, лошадь, корабль и грузовик)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad17c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0acfd8f4-5f98-4f85-9862-41b4dddcfd11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 660.0822 - accuracy: 0.1613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[660.0822143554688, 0.16130000352859497]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "num_epochs = 200 \n",
    "kernel_size = 3 # использование ядра 3x3 \n",
    "pool_size = 2 #   использование объединения 2х2 \n",
    "conv_depth_1 = 32 #  32 р на слой преобразования\n",
    "conv_depth_2 = 64 # переход на 64 после первого уровня объединения\n",
    "drop_prob_1 = 0.25 #  вероятность 0,25\n",
    "drop_prob_2 = 0.5 #  в плотном слое вероятность 0,5\n",
    "hidden_size = 512 # в плотном слое 512 нейронов\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() \n",
    "num_train, depth, height, width = X_train.shape \n",
    "num_test = X_test.shape[0] \n",
    "num_classes = np.unique(y_train).shape[0]\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= np.max(X_train)\n",
    "X_test /= np.max(X_train) \n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) \n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) \n",
    "\n",
    "\n",
    "inp = Input(shape=(depth, height, width)) # N.B. глубина занимает первое место в Керасе\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(inp) #устарело\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)  #Для предотвращения переобучения\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size),padding='same')(conv_4) # padding - сохранять\n",
    "#размер исходного изображения, рисунок дополняется нулями по краям. \n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "#Теперь выровняйте до 1D, примените Плотный -> ReLU (с выпадением) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "model = Model(inputs=inp, outputs=out) # Чтобы определить модель, просто укажите ее входные и выходные слои\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=0, validation_split=0.1) # \n",
    "model.evaluate(X_test, Y_test, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8557f67-cb0d-4a0b-acc3-4fd5edf32e23",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.7983 - accuracy: 0.3227 - val_loss: 1.6044 - val_accuracy: 0.3990\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5472 - accuracy: 0.4249 - val_loss: 1.4703 - val_accuracy: 0.4514\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.4394 - accuracy: 0.4695 - val_loss: 1.4544 - val_accuracy: 0.4806\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3750 - accuracy: 0.4940 - val_loss: 1.3621 - val_accuracy: 0.4998\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3316 - accuracy: 0.5140 - val_loss: 1.3340 - val_accuracy: 0.5154\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.2920 - accuracy: 0.5289 - val_loss: 1.3242 - val_accuracy: 0.5192\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.2619 - accuracy: 0.5429 - val_loss: 1.3324 - val_accuracy: 0.5118\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.2356 - accuracy: 0.5518 - val_loss: 1.3145 - val_accuracy: 0.5266\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.2175 - accuracy: 0.5599 - val_loss: 1.3081 - val_accuracy: 0.5292\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1934 - accuracy: 0.5679 - val_loss: 1.2589 - val_accuracy: 0.5448\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1749 - accuracy: 0.5756 - val_loss: 1.2530 - val_accuracy: 0.5434\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1605 - accuracy: 0.5803 - val_loss: 1.2583 - val_accuracy: 0.5472\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1445 - accuracy: 0.5826 - val_loss: 1.2544 - val_accuracy: 0.5462\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1301 - accuracy: 0.5902 - val_loss: 1.2664 - val_accuracy: 0.5458\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.1138 - accuracy: 0.5991 - val_loss: 1.2373 - val_accuracy: 0.5534\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1002 - accuracy: 0.6029 - val_loss: 1.2308 - val_accuracy: 0.5544\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0890 - accuracy: 0.6070 - val_loss: 1.2310 - val_accuracy: 0.5620\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0749 - accuracy: 0.6099 - val_loss: 1.2540 - val_accuracy: 0.5498\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0635 - accuracy: 0.6133 - val_loss: 1.2582 - val_accuracy: 0.5550\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0539 - accuracy: 0.6164 - val_loss: 1.2340 - val_accuracy: 0.5720\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0432 - accuracy: 0.6199 - val_loss: 1.2498 - val_accuracy: 0.5644\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0358 - accuracy: 0.6236 - val_loss: 1.2814 - val_accuracy: 0.5530\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0207 - accuracy: 0.6274 - val_loss: 1.2642 - val_accuracy: 0.5484\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0092 - accuracy: 0.6322 - val_loss: 1.2673 - val_accuracy: 0.5574\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9992 - accuracy: 0.6343 - val_loss: 1.2618 - val_accuracy: 0.5600\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9890 - accuracy: 0.6408 - val_loss: 1.2833 - val_accuracy: 0.5502\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9774 - accuracy: 0.6427 - val_loss: 1.2649 - val_accuracy: 0.5648\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9713 - accuracy: 0.6448 - val_loss: 1.2899 - val_accuracy: 0.5594\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9558 - accuracy: 0.6489 - val_loss: 1.3099 - val_accuracy: 0.5548\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9479 - accuracy: 0.6538 - val_loss: 1.3176 - val_accuracy: 0.5604\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9374 - accuracy: 0.6561 - val_loss: 1.3138 - val_accuracy: 0.5532\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9251 - accuracy: 0.6575 - val_loss: 1.3057 - val_accuracy: 0.5576\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9199 - accuracy: 0.6627 - val_loss: 1.3502 - val_accuracy: 0.5622\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9057 - accuracy: 0.6668 - val_loss: 1.3344 - val_accuracy: 0.5604\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8960 - accuracy: 0.6691 - val_loss: 1.3358 - val_accuracy: 0.5538\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8843 - accuracy: 0.6729 - val_loss: 1.3990 - val_accuracy: 0.5362\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8719 - accuracy: 0.6776 - val_loss: 1.3788 - val_accuracy: 0.5580\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8666 - accuracy: 0.6783 - val_loss: 1.3951 - val_accuracy: 0.5464\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8558 - accuracy: 0.6826 - val_loss: 1.3893 - val_accuracy: 0.5548\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8485 - accuracy: 0.6872 - val_loss: 1.4429 - val_accuracy: 0.5546\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8421 - accuracy: 0.6891 - val_loss: 1.4381 - val_accuracy: 0.5514\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8299 - accuracy: 0.6934 - val_loss: 1.4441 - val_accuracy: 0.5496\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8243 - accuracy: 0.6941 - val_loss: 1.4661 - val_accuracy: 0.5472\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8106 - accuracy: 0.6994 - val_loss: 1.4816 - val_accuracy: 0.5470\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8031 - accuracy: 0.7022 - val_loss: 1.4938 - val_accuracy: 0.5488\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7926 - accuracy: 0.7074 - val_loss: 1.5117 - val_accuracy: 0.5438\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7862 - accuracy: 0.7077 - val_loss: 1.5253 - val_accuracy: 0.5460\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7776 - accuracy: 0.7123 - val_loss: 1.5657 - val_accuracy: 0.5474\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7690 - accuracy: 0.7138 - val_loss: 1.5691 - val_accuracy: 0.5308\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7620 - accuracy: 0.7162 - val_loss: 1.6016 - val_accuracy: 0.5328\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7539 - accuracy: 0.7190 - val_loss: 1.5616 - val_accuracy: 0.5356\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7397 - accuracy: 0.7251 - val_loss: 1.6185 - val_accuracy: 0.5344\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7322 - accuracy: 0.7278 - val_loss: 1.6524 - val_accuracy: 0.5426\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7322 - accuracy: 0.7268 - val_loss: 1.6486 - val_accuracy: 0.5332\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7240 - accuracy: 0.7303 - val_loss: 1.6788 - val_accuracy: 0.5360\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7099 - accuracy: 0.7352 - val_loss: 1.6873 - val_accuracy: 0.5370\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7089 - accuracy: 0.7368 - val_loss: 1.7031 - val_accuracy: 0.5414\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6974 - accuracy: 0.7386 - val_loss: 1.8072 - val_accuracy: 0.5316\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6908 - accuracy: 0.7424 - val_loss: 1.7975 - val_accuracy: 0.5322\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6860 - accuracy: 0.7441 - val_loss: 1.7484 - val_accuracy: 0.5288\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6770 - accuracy: 0.7479 - val_loss: 1.8495 - val_accuracy: 0.5320\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6719 - accuracy: 0.7490 - val_loss: 1.8077 - val_accuracy: 0.5344\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6663 - accuracy: 0.7503 - val_loss: 1.8003 - val_accuracy: 0.5348\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6575 - accuracy: 0.7532 - val_loss: 1.8326 - val_accuracy: 0.5288\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6573 - accuracy: 0.7536 - val_loss: 1.8836 - val_accuracy: 0.5260\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6488 - accuracy: 0.7568 - val_loss: 1.9534 - val_accuracy: 0.5370\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6422 - accuracy: 0.7598 - val_loss: 1.9267 - val_accuracy: 0.5324\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6378 - accuracy: 0.7609 - val_loss: 1.9252 - val_accuracy: 0.5336\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6298 - accuracy: 0.7652 - val_loss: 1.9816 - val_accuracy: 0.5304\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6282 - accuracy: 0.7634 - val_loss: 2.0256 - val_accuracy: 0.5324\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6189 - accuracy: 0.7666 - val_loss: 1.9593 - val_accuracy: 0.5218\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6127 - accuracy: 0.7685 - val_loss: 2.0184 - val_accuracy: 0.5278\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6140 - accuracy: 0.7700 - val_loss: 2.1169 - val_accuracy: 0.5218\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6099 - accuracy: 0.7728 - val_loss: 2.0390 - val_accuracy: 0.5246\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5968 - accuracy: 0.7764 - val_loss: 2.0508 - val_accuracy: 0.5218\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5919 - accuracy: 0.7758 - val_loss: 2.1408 - val_accuracy: 0.5264\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6075 - accuracy: 0.7737 - val_loss: 2.1686 - val_accuracy: 0.5228\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5827 - accuracy: 0.7816 - val_loss: 2.1464 - val_accuracy: 0.5324\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5801 - accuracy: 0.7830 - val_loss: 2.1742 - val_accuracy: 0.5262\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5774 - accuracy: 0.7829 - val_loss: 2.1670 - val_accuracy: 0.5238\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5700 - accuracy: 0.7853 - val_loss: 2.2322 - val_accuracy: 0.5232\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5700 - accuracy: 0.7873 - val_loss: 2.2271 - val_accuracy: 0.5224\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5636 - accuracy: 0.7896 - val_loss: 2.2091 - val_accuracy: 0.5276\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5668 - accuracy: 0.7886 - val_loss: 2.2919 - val_accuracy: 0.5264\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5614 - accuracy: 0.7908 - val_loss: 2.3570 - val_accuracy: 0.5240\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5524 - accuracy: 0.7914 - val_loss: 2.3114 - val_accuracy: 0.5212\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5500 - accuracy: 0.7935 - val_loss: 2.3542 - val_accuracy: 0.5248\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5430 - accuracy: 0.7952 - val_loss: 2.3193 - val_accuracy: 0.5322\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5418 - accuracy: 0.7960 - val_loss: 2.3409 - val_accuracy: 0.5256\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5296 - accuracy: 0.8019 - val_loss: 2.3781 - val_accuracy: 0.5148\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5320 - accuracy: 0.8012 - val_loss: 2.3471 - val_accuracy: 0.5144\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5310 - accuracy: 0.8016 - val_loss: 2.5084 - val_accuracy: 0.5188\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5302 - accuracy: 0.8004 - val_loss: 2.4523 - val_accuracy: 0.5154\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5199 - accuracy: 0.8020 - val_loss: 2.4479 - val_accuracy: 0.5122\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5227 - accuracy: 0.8048 - val_loss: 2.4869 - val_accuracy: 0.5220\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5187 - accuracy: 0.8056 - val_loss: 2.4890 - val_accuracy: 0.5086\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5178 - accuracy: 0.8052 - val_loss: 2.6274 - val_accuracy: 0.5156\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5114 - accuracy: 0.8079 - val_loss: 2.6228 - val_accuracy: 0.5108\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5178 - accuracy: 0.8074 - val_loss: 2.5925 - val_accuracy: 0.5118\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5085 - accuracy: 0.8076 - val_loss: 2.6643 - val_accuracy: 0.5146\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5068 - accuracy: 0.8083 - val_loss: 2.6132 - val_accuracy: 0.5140\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5033 - accuracy: 0.8108 - val_loss: 2.5961 - val_accuracy: 0.5018\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4942 - accuracy: 0.8151 - val_loss: 2.6980 - val_accuracy: 0.5154\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4981 - accuracy: 0.8134 - val_loss: 2.6799 - val_accuracy: 0.5208\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4983 - accuracy: 0.8133 - val_loss: 2.7499 - val_accuracy: 0.5152\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4898 - accuracy: 0.8171 - val_loss: 2.8167 - val_accuracy: 0.5154\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4923 - accuracy: 0.8174 - val_loss: 2.7269 - val_accuracy: 0.5092\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4909 - accuracy: 0.8160 - val_loss: 2.8161 - val_accuracy: 0.5128\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4874 - accuracy: 0.8172 - val_loss: 2.7450 - val_accuracy: 0.5058\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4770 - accuracy: 0.8226 - val_loss: 2.7504 - val_accuracy: 0.5174\n",
      "Epoch 111/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4787 - accuracy: 0.8182 - val_loss: 2.8338 - val_accuracy: 0.5166\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4740 - accuracy: 0.8220 - val_loss: 2.7857 - val_accuracy: 0.5116\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4776 - accuracy: 0.8215 - val_loss: 2.9518 - val_accuracy: 0.5100\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4783 - accuracy: 0.8205 - val_loss: 2.9607 - val_accuracy: 0.5044\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4685 - accuracy: 0.8256 - val_loss: 2.9359 - val_accuracy: 0.5126\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4819 - accuracy: 0.8211 - val_loss: 2.9948 - val_accuracy: 0.5114\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4759 - accuracy: 0.8215 - val_loss: 2.9324 - val_accuracy: 0.5082\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4588 - accuracy: 0.8283 - val_loss: 2.8796 - val_accuracy: 0.5164\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4705 - accuracy: 0.8240 - val_loss: 2.9985 - val_accuracy: 0.5144\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4651 - accuracy: 0.8260 - val_loss: 2.8864 - val_accuracy: 0.5056\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4698 - accuracy: 0.8246 - val_loss: 2.9987 - val_accuracy: 0.5176\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4646 - accuracy: 0.8258 - val_loss: 2.9726 - val_accuracy: 0.4962\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4584 - accuracy: 0.8291 - val_loss: 3.1627 - val_accuracy: 0.5122\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4609 - accuracy: 0.8278 - val_loss: 3.0354 - val_accuracy: 0.5146\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4558 - accuracy: 0.8305 - val_loss: 3.0779 - val_accuracy: 0.5144\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4492 - accuracy: 0.8302 - val_loss: 3.0921 - val_accuracy: 0.5064\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4398 - accuracy: 0.8359 - val_loss: 3.1119 - val_accuracy: 0.5112\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4480 - accuracy: 0.8330 - val_loss: 2.9678 - val_accuracy: 0.5074\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4507 - accuracy: 0.8312 - val_loss: 3.1342 - val_accuracy: 0.5232\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4423 - accuracy: 0.8336 - val_loss: 3.1607 - val_accuracy: 0.5104\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4359 - accuracy: 0.8368 - val_loss: 3.1730 - val_accuracy: 0.5052\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4423 - accuracy: 0.8348 - val_loss: 3.1581 - val_accuracy: 0.5042\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4437 - accuracy: 0.8348 - val_loss: 3.1166 - val_accuracy: 0.5070\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4421 - accuracy: 0.8354 - val_loss: 3.2178 - val_accuracy: 0.5096\n",
      "Epoch 135/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4387 - accuracy: 0.8368 - val_loss: 3.0745 - val_accuracy: 0.4986\n",
      "Epoch 136/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4399 - accuracy: 0.8334 - val_loss: 3.1494 - val_accuracy: 0.5020\n",
      "Epoch 137/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4274 - accuracy: 0.8406 - val_loss: 3.3111 - val_accuracy: 0.4962\n",
      "Epoch 138/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4483 - accuracy: 0.8356 - val_loss: 3.1859 - val_accuracy: 0.5020\n",
      "Epoch 139/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4334 - accuracy: 0.8395 - val_loss: 3.3077 - val_accuracy: 0.5148\n",
      "Epoch 140/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4243 - accuracy: 0.8425 - val_loss: 3.3303 - val_accuracy: 0.5174\n",
      "Epoch 141/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4343 - accuracy: 0.8398 - val_loss: 3.3271 - val_accuracy: 0.4930\n",
      "Epoch 142/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4232 - accuracy: 0.8432 - val_loss: 3.2607 - val_accuracy: 0.5066\n",
      "Epoch 143/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4259 - accuracy: 0.8425 - val_loss: 3.2538 - val_accuracy: 0.5066\n",
      "Epoch 144/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4236 - accuracy: 0.8427 - val_loss: 3.2722 - val_accuracy: 0.5068\n",
      "Epoch 145/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4303 - accuracy: 0.8411 - val_loss: 3.2937 - val_accuracy: 0.5086\n",
      "Epoch 146/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4236 - accuracy: 0.8432 - val_loss: 3.3764 - val_accuracy: 0.5092\n",
      "Epoch 147/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4279 - accuracy: 0.8417 - val_loss: 3.3531 - val_accuracy: 0.5128\n",
      "Epoch 148/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4121 - accuracy: 0.8469 - val_loss: 3.4225 - val_accuracy: 0.5036\n",
      "Epoch 149/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4164 - accuracy: 0.8462 - val_loss: 3.3688 - val_accuracy: 0.4982\n",
      "Epoch 150/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4204 - accuracy: 0.8452 - val_loss: 3.4590 - val_accuracy: 0.4946\n",
      "Epoch 151/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4219 - accuracy: 0.8453 - val_loss: 3.3158 - val_accuracy: 0.5028\n",
      "Epoch 152/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4144 - accuracy: 0.8448 - val_loss: 3.5464 - val_accuracy: 0.5040\n",
      "Epoch 153/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4135 - accuracy: 0.8462 - val_loss: 3.4837 - val_accuracy: 0.5064\n",
      "Epoch 154/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4189 - accuracy: 0.8431 - val_loss: 3.4630 - val_accuracy: 0.5012\n",
      "Epoch 155/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4147 - accuracy: 0.8467 - val_loss: 3.5391 - val_accuracy: 0.5134\n",
      "Epoch 156/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4157 - accuracy: 0.8454 - val_loss: 3.5500 - val_accuracy: 0.4952\n",
      "Epoch 157/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4126 - accuracy: 0.8486 - val_loss: 3.6071 - val_accuracy: 0.5174\n",
      "Epoch 158/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4079 - accuracy: 0.8498 - val_loss: 3.5149 - val_accuracy: 0.5092\n",
      "Epoch 159/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4079 - accuracy: 0.8496 - val_loss: 3.3971 - val_accuracy: 0.5024\n",
      "Epoch 160/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3986 - accuracy: 0.8517 - val_loss: 3.4659 - val_accuracy: 0.4994\n",
      "Epoch 161/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4086 - accuracy: 0.8484 - val_loss: 3.5637 - val_accuracy: 0.5090\n",
      "Epoch 162/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4140 - accuracy: 0.8466 - val_loss: 3.5090 - val_accuracy: 0.5044\n",
      "Epoch 163/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4013 - accuracy: 0.8507 - val_loss: 3.7655 - val_accuracy: 0.4982\n",
      "Epoch 164/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3981 - accuracy: 0.8525 - val_loss: 3.6418 - val_accuracy: 0.5026\n",
      "Epoch 165/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4002 - accuracy: 0.8522 - val_loss: 3.6647 - val_accuracy: 0.5064\n",
      "Epoch 166/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3940 - accuracy: 0.8533 - val_loss: 3.6647 - val_accuracy: 0.5054\n",
      "Epoch 167/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4031 - accuracy: 0.8501 - val_loss: 3.7190 - val_accuracy: 0.4972\n",
      "Epoch 168/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4110 - accuracy: 0.8493 - val_loss: 3.6097 - val_accuracy: 0.5094\n",
      "Epoch 169/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4001 - accuracy: 0.8532 - val_loss: 3.6732 - val_accuracy: 0.5004\n",
      "Epoch 170/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4077 - accuracy: 0.8505 - val_loss: 3.7184 - val_accuracy: 0.5016\n",
      "Epoch 171/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4141 - accuracy: 0.8490 - val_loss: 3.8303 - val_accuracy: 0.5068\n",
      "Epoch 172/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3936 - accuracy: 0.8554 - val_loss: 3.6610 - val_accuracy: 0.5070\n",
      "Epoch 173/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3853 - accuracy: 0.8575 - val_loss: 3.7781 - val_accuracy: 0.5032\n",
      "Epoch 174/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4165 - accuracy: 0.8471 - val_loss: 3.6665 - val_accuracy: 0.5026\n",
      "Epoch 175/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3966 - accuracy: 0.8526 - val_loss: 3.6056 - val_accuracy: 0.5028\n",
      "Epoch 176/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3996 - accuracy: 0.8540 - val_loss: 3.7813 - val_accuracy: 0.5004\n",
      "Epoch 177/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3869 - accuracy: 0.8568 - val_loss: 3.7633 - val_accuracy: 0.5014\n",
      "Epoch 178/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4042 - accuracy: 0.8526 - val_loss: 3.7185 - val_accuracy: 0.5014\n",
      "Epoch 179/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3898 - accuracy: 0.8559 - val_loss: 3.8617 - val_accuracy: 0.4984\n",
      "Epoch 180/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3961 - accuracy: 0.8550 - val_loss: 3.7446 - val_accuracy: 0.5000\n",
      "Epoch 181/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3838 - accuracy: 0.8576 - val_loss: 3.7083 - val_accuracy: 0.4942\n",
      "Epoch 182/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3838 - accuracy: 0.8580 - val_loss: 3.9250 - val_accuracy: 0.4954\n",
      "Epoch 183/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3959 - accuracy: 0.8546 - val_loss: 3.6783 - val_accuracy: 0.5040\n",
      "Epoch 184/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3766 - accuracy: 0.8630 - val_loss: 3.7891 - val_accuracy: 0.4940\n",
      "Epoch 185/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3986 - accuracy: 0.8553 - val_loss: 3.7357 - val_accuracy: 0.5014\n",
      "Epoch 186/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3902 - accuracy: 0.8578 - val_loss: 3.7904 - val_accuracy: 0.5066\n",
      "Epoch 187/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3870 - accuracy: 0.8561 - val_loss: 3.8731 - val_accuracy: 0.4986\n",
      "Epoch 188/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3904 - accuracy: 0.8574 - val_loss: 3.8143 - val_accuracy: 0.4988\n",
      "Epoch 189/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3874 - accuracy: 0.8580 - val_loss: 3.8205 - val_accuracy: 0.4984\n",
      "Epoch 190/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3641 - accuracy: 0.8648 - val_loss: 3.8076 - val_accuracy: 0.4936\n",
      "Epoch 191/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3923 - accuracy: 0.8575 - val_loss: 4.0542 - val_accuracy: 0.5074\n",
      "Epoch 192/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3799 - accuracy: 0.8609 - val_loss: 3.8632 - val_accuracy: 0.5002\n",
      "Epoch 193/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3912 - accuracy: 0.8583 - val_loss: 4.0248 - val_accuracy: 0.5002\n",
      "Epoch 194/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3879 - accuracy: 0.8581 - val_loss: 3.7959 - val_accuracy: 0.4910\n",
      "Epoch 195/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3673 - accuracy: 0.8641 - val_loss: 4.0266 - val_accuracy: 0.4974\n",
      "Epoch 196/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3924 - accuracy: 0.8580 - val_loss: 3.9421 - val_accuracy: 0.4878\n",
      "Epoch 197/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3796 - accuracy: 0.8611 - val_loss: 4.1484 - val_accuracy: 0.4980\n",
      "Epoch 198/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3757 - accuracy: 0.8617 - val_loss: 3.9470 - val_accuracy: 0.4962\n",
      "Epoch 199/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3886 - accuracy: 0.8588 - val_loss: 3.8949 - val_accuracy: 0.5020\n",
      "Epoch 200/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3774 - accuracy: 0.8617 - val_loss: 4.1092 - val_accuracy: 0.5072\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1916.4426 - accuracy: 0.2549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1916.442626953125, 0.2549000084400177]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "num_epochs = 200 \n",
    "kernel_size = 3 # использование ядра 3x3 \n",
    "pool_size = 2 # использование объединения 2х2 \n",
    "conv_depth_1 = 32 #  32 ядра на слой преобразования\n",
    "conv_depth_2 = 64 # переход на 64 после первого уровня объединения\n",
    "drop_prob_1 = 0.25 # выбывает после объединения с вероятностью 0,25   мы будем применять dropout после каждого слоя подвыборки, а также после полносвязного слоя;\n",
    "drop_prob_2 = 0.5 # выпадают в плотном слое с вероятностью 0,5\n",
    "hidden_size = 512 # в полносвязном  слое будет 512 нейронов \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # извлечение данных CIFAR-10\n",
    "num_train, depth, height, width = X_train.shape # в CIFAR-10 содержится 50000 обучающих примеров\n",
    "num_test = X_test.shape[0] # в CIFAR-10 содержится 10000 тестовых примеров\n",
    "num_classes = np.unique(y_train).shape[0] # существует 10 классов изображений\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "X_test /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # кодирование тренировачных данных\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # кодирование тестировочных данных\n",
    "\n",
    "\n",
    "inp = Input(shape=(depth, height, width)) # обратите внимание, глубина занимает первое место в Керасе\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(inp) #устарело\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "#drop_1 = Dropout(drop_prob_1)(pool_1)  #Регуляризация – это любая модификация алгоритма обучения, предпринятая с целью уменьшить его ошибку обобщения, не уменьшая ошибку обучения.\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(pool_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size),padding='same')(conv_4) # padding='same' входное изображение должно иметь нулевое заполнение, чтобы вывод в свертке не отличался по размеру от ввода. \n",
    "#drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "#Теперь выровняйте до 1D, примените Плотный -> ReLU (с выпадением) -> softmax\n",
    "flat = Flatten()(pool_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(hidden)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out) # Чтобы определить модель, просто укажите ее входные и выходные слои\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1) # verbose=1 - индикатор выполнения\n",
    "#model.evaluate прогнозирует значения и вычисляет потери и все прикрепленные метрики к модели по заданному набору данных. \n",
    "model.evaluate(X_test, Y_test, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1784fbd-7cda-4634-a4f2-db90333cac7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8389 - accuracy: 0.3038 - val_loss: 1.5586 - val_accuracy: 0.4210\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6038 - accuracy: 0.4070 - val_loss: 1.4777 - val_accuracy: 0.4612\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5142 - accuracy: 0.4449 - val_loss: 1.3818 - val_accuracy: 0.4974\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4501 - accuracy: 0.4696 - val_loss: 1.3227 - val_accuracy: 0.5204\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4015 - accuracy: 0.4936 - val_loss: 1.3213 - val_accuracy: 0.5286\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3594 - accuracy: 0.5094 - val_loss: 1.2786 - val_accuracy: 0.5356\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3311 - accuracy: 0.5183 - val_loss: 1.2371 - val_accuracy: 0.5572\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3034 - accuracy: 0.5280 - val_loss: 1.2377 - val_accuracy: 0.5542\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2834 - accuracy: 0.5381 - val_loss: 1.1997 - val_accuracy: 0.5646\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2619 - accuracy: 0.5466 - val_loss: 1.2091 - val_accuracy: 0.5630\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2370 - accuracy: 0.5542 - val_loss: 1.1943 - val_accuracy: 0.5706\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2212 - accuracy: 0.5606 - val_loss: 1.1819 - val_accuracy: 0.5772\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2079 - accuracy: 0.5681 - val_loss: 1.1887 - val_accuracy: 0.5716\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1939 - accuracy: 0.5738 - val_loss: 1.1591 - val_accuracy: 0.5848\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1785 - accuracy: 0.5767 - val_loss: 1.1718 - val_accuracy: 0.5764\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1679 - accuracy: 0.5828 - val_loss: 1.1688 - val_accuracy: 0.5832\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1598 - accuracy: 0.5857 - val_loss: 1.1569 - val_accuracy: 0.5840\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1511 - accuracy: 0.5904 - val_loss: 1.1365 - val_accuracy: 0.5912\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1395 - accuracy: 0.5943 - val_loss: 1.1385 - val_accuracy: 0.5996\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1314 - accuracy: 0.5951 - val_loss: 1.1482 - val_accuracy: 0.5918\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1168 - accuracy: 0.6035 - val_loss: 1.1364 - val_accuracy: 0.5938\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1186 - accuracy: 0.6014 - val_loss: 1.1633 - val_accuracy: 0.5814\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1099 - accuracy: 0.6028 - val_loss: 1.1360 - val_accuracy: 0.6016\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0908 - accuracy: 0.6092 - val_loss: 1.1405 - val_accuracy: 0.5986\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0928 - accuracy: 0.6118 - val_loss: 1.1678 - val_accuracy: 0.5856\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0853 - accuracy: 0.6151 - val_loss: 1.1272 - val_accuracy: 0.6048\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0815 - accuracy: 0.6135 - val_loss: 1.1364 - val_accuracy: 0.5998\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0646 - accuracy: 0.6210 - val_loss: 1.1217 - val_accuracy: 0.6030\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0647 - accuracy: 0.6219 - val_loss: 1.1322 - val_accuracy: 0.5952\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0591 - accuracy: 0.6212 - val_loss: 1.1393 - val_accuracy: 0.5968\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0504 - accuracy: 0.6268 - val_loss: 1.1360 - val_accuracy: 0.5964\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0429 - accuracy: 0.6280 - val_loss: 1.1151 - val_accuracy: 0.6144\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0473 - accuracy: 0.6292 - val_loss: 1.1290 - val_accuracy: 0.6096\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0349 - accuracy: 0.6325 - val_loss: 1.1100 - val_accuracy: 0.6048\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0299 - accuracy: 0.6346 - val_loss: 1.1388 - val_accuracy: 0.5922\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0293 - accuracy: 0.6343 - val_loss: 1.1164 - val_accuracy: 0.6104\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0249 - accuracy: 0.6371 - val_loss: 1.1245 - val_accuracy: 0.6078\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0205 - accuracy: 0.6374 - val_loss: 1.1167 - val_accuracy: 0.6100\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0152 - accuracy: 0.6402 - val_loss: 1.1441 - val_accuracy: 0.5958\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0111 - accuracy: 0.6424 - val_loss: 1.1107 - val_accuracy: 0.6086\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0130 - accuracy: 0.6412 - val_loss: 1.1152 - val_accuracy: 0.6116\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.9967 - accuracy: 0.6454 - val_loss: 1.1342 - val_accuracy: 0.5978\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0030 - accuracy: 0.6440 - val_loss: 1.1452 - val_accuracy: 0.6044\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.9982 - accuracy: 0.6443 - val_loss: 1.1617 - val_accuracy: 0.5930\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9903 - accuracy: 0.6518 - val_loss: 1.1147 - val_accuracy: 0.6136\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9882 - accuracy: 0.6501 - val_loss: 1.1150 - val_accuracy: 0.6096\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.9867 - accuracy: 0.6482 - val_loss: 1.1135 - val_accuracy: 0.6100\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.9926 - accuracy: 0.6524 - val_loss: 1.1454 - val_accuracy: 0.5988\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.9821 - accuracy: 0.6577 - val_loss: 1.1273 - val_accuracy: 0.6004\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9722 - accuracy: 0.6555 - val_loss: 1.1163 - val_accuracy: 0.6096\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9758 - accuracy: 0.6561 - val_loss: 1.1591 - val_accuracy: 0.5974\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9709 - accuracy: 0.6598 - val_loss: 1.1136 - val_accuracy: 0.6134\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9686 - accuracy: 0.6584 - val_loss: 1.1250 - val_accuracy: 0.6000\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9682 - accuracy: 0.6563 - val_loss: 1.1266 - val_accuracy: 0.6054\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9594 - accuracy: 0.6607 - val_loss: 1.1380 - val_accuracy: 0.6046\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9588 - accuracy: 0.6617 - val_loss: 1.1278 - val_accuracy: 0.6086\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9618 - accuracy: 0.6601 - val_loss: 1.1239 - val_accuracy: 0.6076\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9569 - accuracy: 0.6642 - val_loss: 1.1233 - val_accuracy: 0.6018\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9561 - accuracy: 0.6630 - val_loss: 1.1468 - val_accuracy: 0.6024\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9504 - accuracy: 0.6671 - val_loss: 1.1380 - val_accuracy: 0.6028\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9496 - accuracy: 0.6660 - val_loss: 1.1468 - val_accuracy: 0.5992\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9440 - accuracy: 0.6669 - val_loss: 1.1283 - val_accuracy: 0.6040\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9449 - accuracy: 0.6643 - val_loss: 1.1440 - val_accuracy: 0.6014\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9489 - accuracy: 0.6679 - val_loss: 1.1372 - val_accuracy: 0.6014\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9364 - accuracy: 0.6697 - val_loss: 1.1212 - val_accuracy: 0.6082\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9354 - accuracy: 0.6726 - val_loss: 1.1304 - val_accuracy: 0.6048\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9372 - accuracy: 0.6704 - val_loss: 1.1421 - val_accuracy: 0.6048\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9272 - accuracy: 0.6740 - val_loss: 1.1555 - val_accuracy: 0.6024\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9391 - accuracy: 0.6710 - val_loss: 1.1420 - val_accuracy: 0.6002\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9274 - accuracy: 0.6754 - val_loss: 1.1702 - val_accuracy: 0.5920\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9286 - accuracy: 0.6734 - val_loss: 1.1289 - val_accuracy: 0.6074\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9249 - accuracy: 0.6741 - val_loss: 1.1501 - val_accuracy: 0.6090\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9246 - accuracy: 0.6789 - val_loss: 1.1695 - val_accuracy: 0.5990\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9197 - accuracy: 0.6774 - val_loss: 1.1301 - val_accuracy: 0.6050\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9215 - accuracy: 0.6763 - val_loss: 1.1312 - val_accuracy: 0.6030\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9135 - accuracy: 0.6799 - val_loss: 1.1336 - val_accuracy: 0.6044\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9151 - accuracy: 0.6777 - val_loss: 1.1172 - val_accuracy: 0.6102\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9147 - accuracy: 0.6804 - val_loss: 1.1264 - val_accuracy: 0.6126\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9066 - accuracy: 0.6804 - val_loss: 1.1299 - val_accuracy: 0.6088\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9050 - accuracy: 0.6817 - val_loss: 1.1328 - val_accuracy: 0.6058\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9096 - accuracy: 0.6823 - val_loss: 1.1229 - val_accuracy: 0.6066\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9106 - accuracy: 0.6819 - val_loss: 1.1334 - val_accuracy: 0.6070\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9032 - accuracy: 0.6833 - val_loss: 1.1312 - val_accuracy: 0.6064\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9050 - accuracy: 0.6847 - val_loss: 1.1318 - val_accuracy: 0.6184\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8986 - accuracy: 0.6866 - val_loss: 1.1333 - val_accuracy: 0.6094\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8973 - accuracy: 0.6870 - val_loss: 1.1194 - val_accuracy: 0.6128\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9012 - accuracy: 0.6858 - val_loss: 1.1362 - val_accuracy: 0.6046\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8961 - accuracy: 0.6855 - val_loss: 1.1227 - val_accuracy: 0.6058\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9011 - accuracy: 0.6856 - val_loss: 1.2007 - val_accuracy: 0.5912\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8956 - accuracy: 0.6866 - val_loss: 1.1383 - val_accuracy: 0.6088\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8966 - accuracy: 0.6870 - val_loss: 1.1325 - val_accuracy: 0.6100\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8939 - accuracy: 0.6867 - val_loss: 1.1247 - val_accuracy: 0.6028\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8915 - accuracy: 0.6903 - val_loss: 1.1396 - val_accuracy: 0.6110\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8882 - accuracy: 0.6907 - val_loss: 1.1302 - val_accuracy: 0.6076\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8816 - accuracy: 0.6908 - val_loss: 1.1485 - val_accuracy: 0.6100\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8882 - accuracy: 0.6902 - val_loss: 1.1420 - val_accuracy: 0.6116\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8855 - accuracy: 0.6900 - val_loss: 1.1288 - val_accuracy: 0.6096\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8915 - accuracy: 0.6904 - val_loss: 1.1470 - val_accuracy: 0.5958\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8890 - accuracy: 0.6909 - val_loss: 1.1501 - val_accuracy: 0.6054\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8955 - accuracy: 0.6883 - val_loss: 1.1294 - val_accuracy: 0.6114\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8795 - accuracy: 0.6959 - val_loss: 1.1297 - val_accuracy: 0.6118\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8826 - accuracy: 0.6922 - val_loss: 1.1222 - val_accuracy: 0.6140\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8769 - accuracy: 0.6951 - val_loss: 1.1406 - val_accuracy: 0.6042\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8767 - accuracy: 0.6943 - val_loss: 1.1420 - val_accuracy: 0.6080\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8740 - accuracy: 0.6921 - val_loss: 1.1500 - val_accuracy: 0.6022\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8741 - accuracy: 0.6946 - val_loss: 1.1592 - val_accuracy: 0.5990\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8782 - accuracy: 0.6938 - val_loss: 1.1568 - val_accuracy: 0.6058\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8741 - accuracy: 0.6937 - val_loss: 1.1485 - val_accuracy: 0.5972\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8738 - accuracy: 0.6932 - val_loss: 1.1442 - val_accuracy: 0.6056\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8682 - accuracy: 0.6969 - val_loss: 1.1508 - val_accuracy: 0.6076\n",
      "Epoch 111/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8706 - accuracy: 0.6959 - val_loss: 1.1528 - val_accuracy: 0.6042\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8704 - accuracy: 0.6962 - val_loss: 1.1408 - val_accuracy: 0.6088\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8721 - accuracy: 0.6962 - val_loss: 1.1560 - val_accuracy: 0.6022\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8644 - accuracy: 0.6991 - val_loss: 1.1315 - val_accuracy: 0.6048\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8704 - accuracy: 0.6948 - val_loss: 1.1960 - val_accuracy: 0.5868\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8605 - accuracy: 0.7000 - val_loss: 1.1576 - val_accuracy: 0.6026\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8702 - accuracy: 0.6988 - val_loss: 1.1455 - val_accuracy: 0.6018\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8570 - accuracy: 0.7035 - val_loss: 1.1342 - val_accuracy: 0.6088\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8700 - accuracy: 0.6978 - val_loss: 1.1424 - val_accuracy: 0.5990\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8579 - accuracy: 0.7027 - val_loss: 1.1589 - val_accuracy: 0.6022\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8628 - accuracy: 0.6991 - val_loss: 1.1612 - val_accuracy: 0.6038\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8564 - accuracy: 0.7028 - val_loss: 1.1400 - val_accuracy: 0.6054\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8622 - accuracy: 0.7007 - val_loss: 1.1555 - val_accuracy: 0.6040\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8523 - accuracy: 0.7026 - val_loss: 1.1490 - val_accuracy: 0.6026\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8577 - accuracy: 0.7042 - val_loss: 1.1298 - val_accuracy: 0.6146\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8554 - accuracy: 0.7039 - val_loss: 1.1518 - val_accuracy: 0.6076\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8506 - accuracy: 0.7060 - val_loss: 1.1390 - val_accuracy: 0.6072\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8507 - accuracy: 0.7060 - val_loss: 1.1708 - val_accuracy: 0.6044\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8488 - accuracy: 0.7058 - val_loss: 1.1510 - val_accuracy: 0.6072\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8520 - accuracy: 0.7034 - val_loss: 1.1502 - val_accuracy: 0.6050\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8522 - accuracy: 0.7060 - val_loss: 1.1672 - val_accuracy: 0.5998\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8507 - accuracy: 0.7052 - val_loss: 1.1501 - val_accuracy: 0.6102\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8534 - accuracy: 0.7040 - val_loss: 1.1723 - val_accuracy: 0.5928\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8464 - accuracy: 0.7077 - val_loss: 1.1615 - val_accuracy: 0.6034\n",
      "Epoch 135/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8498 - accuracy: 0.7053 - val_loss: 1.1556 - val_accuracy: 0.6004\n",
      "Epoch 136/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8512 - accuracy: 0.7079 - val_loss: 1.1349 - val_accuracy: 0.6032\n",
      "Epoch 137/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8430 - accuracy: 0.7070 - val_loss: 1.1426 - val_accuracy: 0.6082\n",
      "Epoch 138/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8494 - accuracy: 0.7068 - val_loss: 1.1538 - val_accuracy: 0.6036\n",
      "Epoch 139/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8503 - accuracy: 0.7084 - val_loss: 1.1500 - val_accuracy: 0.6026\n",
      "Epoch 140/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8386 - accuracy: 0.7111 - val_loss: 1.1598 - val_accuracy: 0.6040\n",
      "Epoch 141/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8396 - accuracy: 0.7079 - val_loss: 1.1799 - val_accuracy: 0.6038\n",
      "Epoch 142/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8446 - accuracy: 0.7047 - val_loss: 1.1396 - val_accuracy: 0.5996\n",
      "Epoch 143/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8514 - accuracy: 0.7065 - val_loss: 1.1611 - val_accuracy: 0.6034\n",
      "Epoch 144/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8333 - accuracy: 0.7130 - val_loss: 1.1612 - val_accuracy: 0.6146\n",
      "Epoch 145/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8358 - accuracy: 0.7112 - val_loss: 1.1595 - val_accuracy: 0.6062\n",
      "Epoch 146/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8354 - accuracy: 0.7114 - val_loss: 1.1515 - val_accuracy: 0.6030\n",
      "Epoch 147/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8383 - accuracy: 0.7098 - val_loss: 1.1496 - val_accuracy: 0.6114\n",
      "Epoch 148/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8352 - accuracy: 0.7116 - val_loss: 1.1771 - val_accuracy: 0.6036\n",
      "Epoch 149/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8349 - accuracy: 0.7106 - val_loss: 1.1633 - val_accuracy: 0.6028\n",
      "Epoch 150/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8387 - accuracy: 0.7088 - val_loss: 1.1515 - val_accuracy: 0.6054\n",
      "Epoch 151/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8364 - accuracy: 0.7116 - val_loss: 1.1497 - val_accuracy: 0.6062\n",
      "Epoch 152/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8307 - accuracy: 0.7142 - val_loss: 1.1611 - val_accuracy: 0.6030\n",
      "Epoch 153/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8340 - accuracy: 0.7120 - val_loss: 1.1552 - val_accuracy: 0.6042\n",
      "Epoch 154/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8307 - accuracy: 0.7131 - val_loss: 1.1605 - val_accuracy: 0.6038\n",
      "Epoch 155/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8352 - accuracy: 0.7099 - val_loss: 1.1642 - val_accuracy: 0.6012\n",
      "Epoch 156/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8358 - accuracy: 0.7116 - val_loss: 1.1809 - val_accuracy: 0.6070\n",
      "Epoch 157/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8311 - accuracy: 0.7138 - val_loss: 1.1888 - val_accuracy: 0.5992\n",
      "Epoch 158/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8316 - accuracy: 0.7139 - val_loss: 1.1689 - val_accuracy: 0.5962\n",
      "Epoch 159/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8291 - accuracy: 0.7142 - val_loss: 1.1562 - val_accuracy: 0.6038\n",
      "Epoch 160/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8258 - accuracy: 0.7141 - val_loss: 1.1829 - val_accuracy: 0.5988\n",
      "Epoch 161/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8338 - accuracy: 0.7126 - val_loss: 1.1829 - val_accuracy: 0.5986\n",
      "Epoch 162/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8295 - accuracy: 0.7141 - val_loss: 1.1535 - val_accuracy: 0.6128\n",
      "Epoch 163/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8321 - accuracy: 0.7157 - val_loss: 1.1614 - val_accuracy: 0.6072\n",
      "Epoch 164/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8262 - accuracy: 0.7134 - val_loss: 1.1657 - val_accuracy: 0.6088\n",
      "Epoch 165/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8229 - accuracy: 0.7152 - val_loss: 1.1545 - val_accuracy: 0.6062\n",
      "Epoch 166/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8188 - accuracy: 0.7166 - val_loss: 1.1626 - val_accuracy: 0.6040\n",
      "Epoch 167/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8199 - accuracy: 0.7144 - val_loss: 1.1957 - val_accuracy: 0.6030\n",
      "Epoch 168/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8242 - accuracy: 0.7146 - val_loss: 1.1722 - val_accuracy: 0.6076\n",
      "Epoch 169/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8314 - accuracy: 0.7156 - val_loss: 1.1842 - val_accuracy: 0.6036\n",
      "Epoch 170/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8190 - accuracy: 0.7180 - val_loss: 1.1546 - val_accuracy: 0.6040\n",
      "Epoch 171/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8177 - accuracy: 0.7179 - val_loss: 1.1813 - val_accuracy: 0.6022\n",
      "Epoch 172/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8137 - accuracy: 0.7201 - val_loss: 1.1882 - val_accuracy: 0.5964\n",
      "Epoch 173/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8214 - accuracy: 0.7162 - val_loss: 1.1701 - val_accuracy: 0.5972\n",
      "Epoch 174/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8184 - accuracy: 0.7160 - val_loss: 1.1852 - val_accuracy: 0.6076\n",
      "Epoch 175/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8222 - accuracy: 0.7185 - val_loss: 1.1783 - val_accuracy: 0.5980\n",
      "Epoch 176/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8192 - accuracy: 0.7179 - val_loss: 1.1693 - val_accuracy: 0.6026\n",
      "Epoch 177/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8253 - accuracy: 0.7167 - val_loss: 1.1750 - val_accuracy: 0.6022\n",
      "Epoch 178/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8157 - accuracy: 0.7212 - val_loss: 1.1800 - val_accuracy: 0.6022\n",
      "Epoch 179/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8159 - accuracy: 0.7178 - val_loss: 1.1668 - val_accuracy: 0.6068\n",
      "Epoch 180/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8188 - accuracy: 0.7184 - val_loss: 1.1626 - val_accuracy: 0.6054\n",
      "Epoch 181/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8090 - accuracy: 0.7215 - val_loss: 1.1620 - val_accuracy: 0.6016\n",
      "Epoch 182/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8163 - accuracy: 0.7176 - val_loss: 1.1708 - val_accuracy: 0.6000\n",
      "Epoch 183/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8263 - accuracy: 0.7146 - val_loss: 1.1812 - val_accuracy: 0.6022\n",
      "Epoch 184/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8141 - accuracy: 0.7190 - val_loss: 1.1760 - val_accuracy: 0.5990\n",
      "Epoch 185/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8160 - accuracy: 0.7201 - val_loss: 1.1727 - val_accuracy: 0.6042\n",
      "Epoch 186/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8131 - accuracy: 0.7202 - val_loss: 1.1975 - val_accuracy: 0.5964\n",
      "Epoch 187/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8152 - accuracy: 0.7217 - val_loss: 1.1734 - val_accuracy: 0.6044\n",
      "Epoch 188/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8131 - accuracy: 0.7221 - val_loss: 1.1854 - val_accuracy: 0.5994\n",
      "Epoch 189/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8121 - accuracy: 0.7197 - val_loss: 1.1727 - val_accuracy: 0.6044\n",
      "Epoch 190/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8115 - accuracy: 0.7212 - val_loss: 1.1670 - val_accuracy: 0.6056\n",
      "Epoch 191/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8134 - accuracy: 0.7221 - val_loss: 1.1733 - val_accuracy: 0.6086\n",
      "Epoch 192/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8067 - accuracy: 0.7218 - val_loss: 1.1899 - val_accuracy: 0.6038\n",
      "Epoch 193/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8171 - accuracy: 0.7204 - val_loss: 1.1977 - val_accuracy: 0.5994\n",
      "Epoch 194/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8052 - accuracy: 0.7226 - val_loss: 1.1764 - val_accuracy: 0.6146\n",
      "Epoch 195/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8080 - accuracy: 0.7214 - val_loss: 1.2027 - val_accuracy: 0.6016\n",
      "Epoch 196/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8104 - accuracy: 0.7204 - val_loss: 1.2028 - val_accuracy: 0.5946\n",
      "Epoch 197/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8069 - accuracy: 0.7236 - val_loss: 1.1900 - val_accuracy: 0.6016\n",
      "Epoch 198/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8072 - accuracy: 0.7213 - val_loss: 1.1763 - val_accuracy: 0.6082\n",
      "Epoch 199/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8119 - accuracy: 0.7225 - val_loss: 1.1936 - val_accuracy: 0.6030\n",
      "Epoch 200/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8053 - accuracy: 0.7240 - val_loss: 1.2104 - val_accuracy: 0.6084\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 551.4978 - accuracy: 0.2164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[551.497802734375, 0.21639999747276306]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "num_epochs = 200 \n",
    "kernel_size = 3 # мы будем использовать ядра 3x3 повсюду\n",
    "pool_size = 2 # мы будем использовать объединение 2х2 повсюду\n",
    "conv_depth_1 = 64 # первоначально у нас будет 32 ядра на слой преобразования\n",
    "conv_depth_2 = 128 # переключение на 64 после первого уровня объединения\n",
    "drop_prob_1 = 0.25 # выбывает после объединения с вероятностью 0,25\n",
    "drop_prob_2 = 0.5 # выпадают в плотном слое с вероятностью 0,5\n",
    "hidden_size = 512 # в плотном слое будет 512 нейронов\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # извлечение данных CIFAR-10\n",
    "num_train, depth, height, width = X_train.shape # в CIFAR-10 содержится 50000 обучающих примеров\n",
    "num_test = X_test.shape[0] # в CIFAR-10 содержится 10000 тестовых примеров\n",
    "num_classes = np.unique(y_train).shape[0] # существует 10 классов изображений\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "X_test /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # кодирование тренировачных данных\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # кодирование тестировочных данных\n",
    "\n",
    "\n",
    "inp = Input(shape=(depth, height, width)) # N.B. глубина занимает первое место в Керасе\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(inp) #устарело\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size),padding='same')(conv_4) # padding='same' входное изображение должно иметь нулевое заполнение, чтобы вывод в свертке не отличался по размеру от ввода. \n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "#Теперь выровняйте до 1D, примените Плотный -> ReLU (с выпадением) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "model = Model(inputs=inp, outputs=out) # Чтобы определить модель, просто укажите ее входные и выходные слои\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1) # \n",
    "model.evaluate(X_test, Y_test, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76cda5b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.7983 - accuracy: 0.3281 - val_loss: 1.5034 - val_accuracy: 0.4390\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5417 - accuracy: 0.4312 - val_loss: 1.3625 - val_accuracy: 0.5004\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4616 - accuracy: 0.4657 - val_loss: 1.2962 - val_accuracy: 0.5314\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4109 - accuracy: 0.4841 - val_loss: 1.2573 - val_accuracy: 0.5448\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3654 - accuracy: 0.5087 - val_loss: 1.2059 - val_accuracy: 0.5654\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3366 - accuracy: 0.5202 - val_loss: 1.1655 - val_accuracy: 0.5904\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3042 - accuracy: 0.5300 - val_loss: 1.1854 - val_accuracy: 0.5696\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2865 - accuracy: 0.5417 - val_loss: 1.1335 - val_accuracy: 0.5952\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2676 - accuracy: 0.5439 - val_loss: 1.1076 - val_accuracy: 0.6112\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2466 - accuracy: 0.5551 - val_loss: 1.1031 - val_accuracy: 0.6116\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2347 - accuracy: 0.5566 - val_loss: 1.1557 - val_accuracy: 0.5878\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2230 - accuracy: 0.5640 - val_loss: 1.1010 - val_accuracy: 0.6124\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2031 - accuracy: 0.5716 - val_loss: 1.0951 - val_accuracy: 0.6176\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2004 - accuracy: 0.5711 - val_loss: 1.0931 - val_accuracy: 0.6146\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1909 - accuracy: 0.5773 - val_loss: 1.0885 - val_accuracy: 0.6174\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1790 - accuracy: 0.5818 - val_loss: 1.0659 - val_accuracy: 0.6294\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1718 - accuracy: 0.5864 - val_loss: 1.0730 - val_accuracy: 0.6292\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1623 - accuracy: 0.5880 - val_loss: 1.0610 - val_accuracy: 0.6326\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1577 - accuracy: 0.5898 - val_loss: 1.0541 - val_accuracy: 0.6360\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1502 - accuracy: 0.5908 - val_loss: 1.0735 - val_accuracy: 0.6308\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1410 - accuracy: 0.5933 - val_loss: 1.0373 - val_accuracy: 0.6422\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1343 - accuracy: 0.5949 - val_loss: 1.0607 - val_accuracy: 0.6288\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1387 - accuracy: 0.5956 - val_loss: 1.0614 - val_accuracy: 0.6324\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1305 - accuracy: 0.6013 - val_loss: 1.0570 - val_accuracy: 0.6274\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1260 - accuracy: 0.5978 - val_loss: 1.0370 - val_accuracy: 0.6406\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1192 - accuracy: 0.6027 - val_loss: 1.0455 - val_accuracy: 0.6366\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1182 - accuracy: 0.6064 - val_loss: 1.0376 - val_accuracy: 0.6366\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1056 - accuracy: 0.6073 - val_loss: 1.0234 - val_accuracy: 0.6414\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1044 - accuracy: 0.6104 - val_loss: 1.0418 - val_accuracy: 0.6364\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1043 - accuracy: 0.6083 - val_loss: 1.0326 - val_accuracy: 0.6354\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0916 - accuracy: 0.6116 - val_loss: 1.0270 - val_accuracy: 0.6376\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0974 - accuracy: 0.6118 - val_loss: 1.0167 - val_accuracy: 0.6474\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0921 - accuracy: 0.6145 - val_loss: 1.0214 - val_accuracy: 0.6470\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0879 - accuracy: 0.6142 - val_loss: 1.0285 - val_accuracy: 0.6444\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0886 - accuracy: 0.6156 - val_loss: 1.0083 - val_accuracy: 0.6500\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0854 - accuracy: 0.6139 - val_loss: 1.0227 - val_accuracy: 0.6464\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0794 - accuracy: 0.6173 - val_loss: 1.0205 - val_accuracy: 0.6504\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0740 - accuracy: 0.6192 - val_loss: 1.0301 - val_accuracy: 0.6438\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0745 - accuracy: 0.6193 - val_loss: 1.0221 - val_accuracy: 0.6444\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0741 - accuracy: 0.6216 - val_loss: 1.0085 - val_accuracy: 0.6484\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0721 - accuracy: 0.6226 - val_loss: 0.9972 - val_accuracy: 0.6544\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0686 - accuracy: 0.6215 - val_loss: 1.0377 - val_accuracy: 0.6324\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0668 - accuracy: 0.6236 - val_loss: 1.0064 - val_accuracy: 0.6516\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0666 - accuracy: 0.6236 - val_loss: 1.0244 - val_accuracy: 0.6442\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0647 - accuracy: 0.6242 - val_loss: 1.0310 - val_accuracy: 0.6466\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0529 - accuracy: 0.6292 - val_loss: 1.0072 - val_accuracy: 0.6490\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0491 - accuracy: 0.6303 - val_loss: 1.0480 - val_accuracy: 0.6330\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0542 - accuracy: 0.6264 - val_loss: 1.0194 - val_accuracy: 0.6540\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0534 - accuracy: 0.6285 - val_loss: 1.0307 - val_accuracy: 0.6360\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0553 - accuracy: 0.6278 - val_loss: 1.0065 - val_accuracy: 0.6568\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0452 - accuracy: 0.6322 - val_loss: 0.9942 - val_accuracy: 0.6558\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0457 - accuracy: 0.6313 - val_loss: 1.0024 - val_accuracy: 0.6526\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0465 - accuracy: 0.6323 - val_loss: 1.0191 - val_accuracy: 0.6412\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0454 - accuracy: 0.6324 - val_loss: 1.0236 - val_accuracy: 0.6508\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0447 - accuracy: 0.6327 - val_loss: 0.9993 - val_accuracy: 0.6546\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0397 - accuracy: 0.6328 - val_loss: 1.0133 - val_accuracy: 0.6482\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0391 - accuracy: 0.6331 - val_loss: 1.0058 - val_accuracy: 0.6496\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0331 - accuracy: 0.6334 - val_loss: 0.9932 - val_accuracy: 0.6542\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0375 - accuracy: 0.6351 - val_loss: 0.9832 - val_accuracy: 0.6560\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0349 - accuracy: 0.6332 - val_loss: 0.9896 - val_accuracy: 0.6610\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0305 - accuracy: 0.6376 - val_loss: 0.9828 - val_accuracy: 0.6586\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0281 - accuracy: 0.6369 - val_loss: 0.9891 - val_accuracy: 0.6544\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0344 - accuracy: 0.6354 - val_loss: 0.9938 - val_accuracy: 0.6554\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0262 - accuracy: 0.6357 - val_loss: 0.9870 - val_accuracy: 0.6546\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0266 - accuracy: 0.6379 - val_loss: 0.9962 - val_accuracy: 0.6516\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0242 - accuracy: 0.6415 - val_loss: 0.9989 - val_accuracy: 0.6504\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0297 - accuracy: 0.6359 - val_loss: 0.9970 - val_accuracy: 0.6524\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0199 - accuracy: 0.6399 - val_loss: 0.9746 - val_accuracy: 0.6518\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0186 - accuracy: 0.6408 - val_loss: 0.9828 - val_accuracy: 0.6614\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0211 - accuracy: 0.6400 - val_loss: 0.9926 - val_accuracy: 0.6578\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0209 - accuracy: 0.6406 - val_loss: 0.9731 - val_accuracy: 0.6582\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0184 - accuracy: 0.6414 - val_loss: 0.9978 - val_accuracy: 0.6518\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0155 - accuracy: 0.6422 - val_loss: 0.9847 - val_accuracy: 0.6604\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0168 - accuracy: 0.6400 - val_loss: 0.9832 - val_accuracy: 0.6578\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0162 - accuracy: 0.6420 - val_loss: 0.9838 - val_accuracy: 0.6592\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0175 - accuracy: 0.6464 - val_loss: 0.9789 - val_accuracy: 0.6542\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0121 - accuracy: 0.6426 - val_loss: 0.9647 - val_accuracy: 0.6668\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0123 - accuracy: 0.6439 - val_loss: 0.9714 - val_accuracy: 0.6646\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0125 - accuracy: 0.6462 - val_loss: 0.9736 - val_accuracy: 0.6562\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0111 - accuracy: 0.6431 - val_loss: 0.9918 - val_accuracy: 0.6534\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0090 - accuracy: 0.6460 - val_loss: 0.9734 - val_accuracy: 0.6642\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0102 - accuracy: 0.6416 - val_loss: 0.9991 - val_accuracy: 0.6582\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0063 - accuracy: 0.6483 - val_loss: 0.9794 - val_accuracy: 0.6604\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0111 - accuracy: 0.6450 - val_loss: 0.9857 - val_accuracy: 0.6594\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0095 - accuracy: 0.6423 - val_loss: 0.9926 - val_accuracy: 0.6534\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0061 - accuracy: 0.6448 - val_loss: 0.9737 - val_accuracy: 0.6632\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0045 - accuracy: 0.6487 - val_loss: 0.9836 - val_accuracy: 0.6582\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0035 - accuracy: 0.6482 - val_loss: 0.9692 - val_accuracy: 0.6634\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0026 - accuracy: 0.6460 - val_loss: 0.9742 - val_accuracy: 0.6660\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0052 - accuracy: 0.6447 - val_loss: 0.9938 - val_accuracy: 0.6638\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9999 - accuracy: 0.6503 - val_loss: 0.9960 - val_accuracy: 0.6524\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0003 - accuracy: 0.6474 - val_loss: 0.9736 - val_accuracy: 0.6640\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0018 - accuracy: 0.6494 - val_loss: 0.9786 - val_accuracy: 0.6656\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0061 - accuracy: 0.6469 - val_loss: 0.9674 - val_accuracy: 0.6688\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9996 - accuracy: 0.6472 - val_loss: 0.9630 - val_accuracy: 0.6640\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0012 - accuracy: 0.6459 - val_loss: 0.9760 - val_accuracy: 0.6648\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9999 - accuracy: 0.6470 - val_loss: 0.9965 - val_accuracy: 0.6510\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9980 - accuracy: 0.6511 - val_loss: 0.9744 - val_accuracy: 0.6600\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.9974 - accuracy: 0.6484 - val_loss: 0.9859 - val_accuracy: 0.6540\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9995 - accuracy: 0.6519 - val_loss: 0.9691 - val_accuracy: 0.6650\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9969 - accuracy: 0.6492 - val_loss: 0.9853 - val_accuracy: 0.6592\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9977 - accuracy: 0.6502 - val_loss: 0.9833 - val_accuracy: 0.6644\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9985 - accuracy: 0.6482 - val_loss: 0.9618 - val_accuracy: 0.6620\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9828 - accuracy: 0.6560 - val_loss: 0.9857 - val_accuracy: 0.6602\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9914 - accuracy: 0.6522 - val_loss: 0.9674 - val_accuracy: 0.6690\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9980 - accuracy: 0.6496 - val_loss: 0.9721 - val_accuracy: 0.6614\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9916 - accuracy: 0.6491 - val_loss: 0.9660 - val_accuracy: 0.6634\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9879 - accuracy: 0.6536 - val_loss: 0.9596 - val_accuracy: 0.6728\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9863 - accuracy: 0.6513 - val_loss: 0.9729 - val_accuracy: 0.6698\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9873 - accuracy: 0.6523 - val_loss: 0.9655 - val_accuracy: 0.6656\n",
      "Epoch 111/200\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.9874 - accuracy: 0.6536 - val_loss: 0.9797 - val_accuracy: 0.6638\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9926 - accuracy: 0.6511 - val_loss: 0.9674 - val_accuracy: 0.6626\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9861 - accuracy: 0.6535 - val_loss: 0.9734 - val_accuracy: 0.6554\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9832 - accuracy: 0.6545 - val_loss: 0.9713 - val_accuracy: 0.6656\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9876 - accuracy: 0.6524 - val_loss: 0.9676 - val_accuracy: 0.6640\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9810 - accuracy: 0.6530 - val_loss: 0.9950 - val_accuracy: 0.6548\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9852 - accuracy: 0.6529 - val_loss: 0.9951 - val_accuracy: 0.6538\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9837 - accuracy: 0.6546 - val_loss: 0.9642 - val_accuracy: 0.6658\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9833 - accuracy: 0.6534 - val_loss: 0.9772 - val_accuracy: 0.6648\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9826 - accuracy: 0.6525 - val_loss: 0.9718 - val_accuracy: 0.6664\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9825 - accuracy: 0.6545 - val_loss: 1.0009 - val_accuracy: 0.6542\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9803 - accuracy: 0.6565 - val_loss: 0.9601 - val_accuracy: 0.6684\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9839 - accuracy: 0.6548 - val_loss: 0.9778 - val_accuracy: 0.6564\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9875 - accuracy: 0.6534 - val_loss: 0.9869 - val_accuracy: 0.6492\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9801 - accuracy: 0.6567 - val_loss: 0.9555 - val_accuracy: 0.6712\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9793 - accuracy: 0.6572 - val_loss: 0.9544 - val_accuracy: 0.6728\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.9809 - accuracy: 0.6563 - val_loss: 0.9734 - val_accuracy: 0.6606\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9775 - accuracy: 0.6575 - val_loss: 0.9548 - val_accuracy: 0.6714\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9858 - accuracy: 0.6549 - val_loss: 0.9594 - val_accuracy: 0.6666\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9795 - accuracy: 0.6565 - val_loss: 0.9733 - val_accuracy: 0.6654\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9844 - accuracy: 0.6559 - val_loss: 0.9546 - val_accuracy: 0.6686\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9871 - accuracy: 0.6560 - val_loss: 0.9631 - val_accuracy: 0.6678\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9790 - accuracy: 0.6556 - val_loss: 0.9479 - val_accuracy: 0.6762\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9764 - accuracy: 0.6554 - val_loss: 0.9604 - val_accuracy: 0.6744\n",
      "Epoch 135/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9844 - accuracy: 0.6549 - val_loss: 0.9631 - val_accuracy: 0.6684\n",
      "Epoch 136/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9730 - accuracy: 0.6560 - val_loss: 0.9632 - val_accuracy: 0.6644\n",
      "Epoch 137/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9785 - accuracy: 0.6582 - val_loss: 1.0000 - val_accuracy: 0.6614\n",
      "Epoch 138/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9757 - accuracy: 0.6577 - val_loss: 0.9597 - val_accuracy: 0.6660\n",
      "Epoch 139/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9814 - accuracy: 0.6561 - val_loss: 0.9553 - val_accuracy: 0.6690\n",
      "Epoch 140/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9735 - accuracy: 0.6570 - val_loss: 0.9678 - val_accuracy: 0.6776\n",
      "Epoch 141/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9769 - accuracy: 0.6577 - val_loss: 0.9602 - val_accuracy: 0.6560\n",
      "Epoch 142/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9743 - accuracy: 0.6576 - val_loss: 0.9697 - val_accuracy: 0.6650\n",
      "Epoch 143/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9741 - accuracy: 0.6550 - val_loss: 0.9733 - val_accuracy: 0.6704\n",
      "Epoch 144/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9752 - accuracy: 0.6581 - val_loss: 0.9421 - val_accuracy: 0.6786\n",
      "Epoch 145/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9749 - accuracy: 0.6592 - val_loss: 0.9724 - val_accuracy: 0.6696\n",
      "Epoch 146/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9756 - accuracy: 0.6591 - val_loss: 0.9483 - val_accuracy: 0.6768\n",
      "Epoch 147/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9718 - accuracy: 0.6584 - val_loss: 0.9799 - val_accuracy: 0.6626\n",
      "Epoch 148/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9733 - accuracy: 0.6586 - val_loss: 0.9662 - val_accuracy: 0.6678\n",
      "Epoch 149/200\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 0.9763 - accuracy: 0.6578 - val_loss: 0.9540 - val_accuracy: 0.6730\n",
      "Epoch 150/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9698 - accuracy: 0.6613 - val_loss: 0.9541 - val_accuracy: 0.6666\n",
      "Epoch 151/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9731 - accuracy: 0.6578 - val_loss: 0.9510 - val_accuracy: 0.6734\n",
      "Epoch 152/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9758 - accuracy: 0.6597 - val_loss: 0.9568 - val_accuracy: 0.6764\n",
      "Epoch 153/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9776 - accuracy: 0.6578 - val_loss: 0.9690 - val_accuracy: 0.6684\n",
      "Epoch 154/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9700 - accuracy: 0.6603 - val_loss: 0.9553 - val_accuracy: 0.6730\n",
      "Epoch 155/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9761 - accuracy: 0.6580 - val_loss: 0.9665 - val_accuracy: 0.6634\n",
      "Epoch 156/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9695 - accuracy: 0.6580 - val_loss: 0.9579 - val_accuracy: 0.6704\n",
      "Epoch 157/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9716 - accuracy: 0.6600 - val_loss: 0.9797 - val_accuracy: 0.6628\n",
      "Epoch 158/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9754 - accuracy: 0.6597 - val_loss: 0.9747 - val_accuracy: 0.6674\n",
      "Epoch 159/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9738 - accuracy: 0.6589 - val_loss: 0.9507 - val_accuracy: 0.6776\n",
      "Epoch 160/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9663 - accuracy: 0.6590 - val_loss: 0.9721 - val_accuracy: 0.6608\n",
      "Epoch 161/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9684 - accuracy: 0.6603 - val_loss: 0.9654 - val_accuracy: 0.6610\n",
      "Epoch 162/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9708 - accuracy: 0.6591 - val_loss: 0.9492 - val_accuracy: 0.6778\n",
      "Epoch 163/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9693 - accuracy: 0.6593 - val_loss: 0.9746 - val_accuracy: 0.6662\n",
      "Epoch 164/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9726 - accuracy: 0.6599 - val_loss: 0.9517 - val_accuracy: 0.6796\n",
      "Epoch 165/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9724 - accuracy: 0.6598 - val_loss: 0.9647 - val_accuracy: 0.6682\n",
      "Epoch 166/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9736 - accuracy: 0.6590 - val_loss: 0.9741 - val_accuracy: 0.6610\n",
      "Epoch 167/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9655 - accuracy: 0.6608 - val_loss: 0.9638 - val_accuracy: 0.6644\n",
      "Epoch 168/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9706 - accuracy: 0.6590 - val_loss: 0.9853 - val_accuracy: 0.6614\n",
      "Epoch 169/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9665 - accuracy: 0.6599 - val_loss: 0.9450 - val_accuracy: 0.6776\n",
      "Epoch 170/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9661 - accuracy: 0.6611 - val_loss: 0.9594 - val_accuracy: 0.6742\n",
      "Epoch 171/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9670 - accuracy: 0.6592 - val_loss: 0.9574 - val_accuracy: 0.6678\n",
      "Epoch 172/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9622 - accuracy: 0.6618 - val_loss: 0.9469 - val_accuracy: 0.6672\n",
      "Epoch 173/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9722 - accuracy: 0.6636 - val_loss: 0.9627 - val_accuracy: 0.6728\n",
      "Epoch 174/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9668 - accuracy: 0.6623 - val_loss: 0.9612 - val_accuracy: 0.6716\n",
      "Epoch 175/200\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9700 - accuracy: 0.6592 - val_loss: 0.9738 - val_accuracy: 0.6668\n",
      "Epoch 176/200\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9598 - accuracy: 0.6638 - val_loss: 0.9501 - val_accuracy: 0.6658\n",
      "Epoch 177/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9669 - accuracy: 0.6596 - val_loss: 0.9422 - val_accuracy: 0.6826\n",
      "Epoch 178/200\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9589 - accuracy: 0.6626 - val_loss: 0.9388 - val_accuracy: 0.6772\n",
      "Epoch 179/200\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 0.9623 - accuracy: 0.6654 - val_loss: 0.9510 - val_accuracy: 0.6778\n",
      "Epoch 180/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9675 - accuracy: 0.6590 - val_loss: 0.9681 - val_accuracy: 0.6642\n",
      "Epoch 181/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9704 - accuracy: 0.6594 - val_loss: 0.9464 - val_accuracy: 0.6744\n",
      "Epoch 182/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9689 - accuracy: 0.6581 - val_loss: 0.9477 - val_accuracy: 0.6792\n",
      "Epoch 183/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9625 - accuracy: 0.6620 - val_loss: 0.9502 - val_accuracy: 0.6766\n",
      "Epoch 184/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9623 - accuracy: 0.6642 - val_loss: 0.9531 - val_accuracy: 0.6750\n",
      "Epoch 185/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9679 - accuracy: 0.6614 - val_loss: 0.9631 - val_accuracy: 0.6712\n",
      "Epoch 186/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9691 - accuracy: 0.6613 - val_loss: 0.9497 - val_accuracy: 0.6700\n",
      "Epoch 187/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9586 - accuracy: 0.6630 - val_loss: 0.9685 - val_accuracy: 0.6658\n",
      "Epoch 188/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9626 - accuracy: 0.6610 - val_loss: 0.9527 - val_accuracy: 0.6730\n",
      "Epoch 189/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9615 - accuracy: 0.6621 - val_loss: 0.9454 - val_accuracy: 0.6744\n",
      "Epoch 190/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9618 - accuracy: 0.6641 - val_loss: 0.9456 - val_accuracy: 0.6790\n",
      "Epoch 191/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9662 - accuracy: 0.6609 - val_loss: 0.9513 - val_accuracy: 0.6712\n",
      "Epoch 192/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9580 - accuracy: 0.6633 - val_loss: 0.9556 - val_accuracy: 0.6680\n",
      "Epoch 193/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9631 - accuracy: 0.6614 - val_loss: 0.9558 - val_accuracy: 0.6760\n",
      "Epoch 194/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9614 - accuracy: 0.6614 - val_loss: 0.9459 - val_accuracy: 0.6700\n",
      "Epoch 195/200\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.9679 - accuracy: 0.6597 - val_loss: 0.9637 - val_accuracy: 0.6702\n",
      "Epoch 196/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9619 - accuracy: 0.6610 - val_loss: 0.9554 - val_accuracy: 0.6770\n",
      "Epoch 197/200\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.9678 - accuracy: 0.6624 - val_loss: 0.9686 - val_accuracy: 0.6722\n",
      "Epoch 198/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9657 - accuracy: 0.6628 - val_loss: 0.9559 - val_accuracy: 0.6704\n",
      "Epoch 199/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9553 - accuracy: 0.6634 - val_loss: 0.9416 - val_accuracy: 0.6832\n",
      "Epoch 200/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9636 - accuracy: 0.6619 - val_loss: 0.9466 - val_accuracy: 0.6780\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 518.6017 - accuracy: 0.1691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[518.6016845703125, 0.16910000145435333]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "num_epochs = 200 \n",
    "kernel_size = 2 # мы будем использовать ядра 3x3 повсюду\n",
    "pool_size = 2 # мы будем использовать объединение 2х2 повсюду\n",
    "conv_depth_1 = 32 # первоначально у нас будет 32 ядра на слой преобразования\n",
    "conv_depth_2 = 64 # переключение на 64 после первого уровня объединения\n",
    "drop_prob_1 = 0.25 # выбывает после объединения с вероятностью 0,25\n",
    "drop_prob_2 = 0.5 # выпадают в плотном слое с вероятностью 0,5\n",
    "hidden_size = 512 # в плотном слое будет 512 нейронов\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # извлечение данных CIFAR-10\n",
    "num_train, depth, height, width = X_train.shape # в CIFAR-10 содержится 50000 обучающих примеров\n",
    "num_test = X_test.shape[0] # в CIFAR-10 содержится 10000 тестовых примеров\n",
    "num_classes = np.unique(y_train).shape[0] # существует 10 классов изображений\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "X_test /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # кодирование тренировачных данных\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # кодирование тестировочных данных\n",
    "\n",
    "\n",
    "inp = Input(shape=(depth, height, width)) # N.B. глубина занимает первое место в Керасе\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(inp) #устарело\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size),padding='same')(conv_4) # padding='same' входное изображение должно иметь нулевое заполнение, чтобы вывод в свертке не отличался по размеру от ввода. \n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "#Теперь выровняйте до 1D, примените Плотный -> ReLU (с выпадением) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "model = Model(inputs=inp, outputs=out) # Чтобы определить модель, просто укажите ее входные и выходные слои\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1) # \n",
    "model.evaluate(X_test, Y_test, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68f452c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.9883 - accuracy: 0.2312 - val_loss: 1.8137 - val_accuracy: 0.3108\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7936 - accuracy: 0.3249 - val_loss: 1.6782 - val_accuracy: 0.3890\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7052 - accuracy: 0.3647 - val_loss: 1.5901 - val_accuracy: 0.4246\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6577 - accuracy: 0.3882 - val_loss: 1.5584 - val_accuracy: 0.4266\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6189 - accuracy: 0.4005 - val_loss: 1.5131 - val_accuracy: 0.4446\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5897 - accuracy: 0.4157 - val_loss: 1.5003 - val_accuracy: 0.4382\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5664 - accuracy: 0.4255 - val_loss: 1.4465 - val_accuracy: 0.4606\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5485 - accuracy: 0.4307 - val_loss: 1.4373 - val_accuracy: 0.4768\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5270 - accuracy: 0.4425 - val_loss: 1.4337 - val_accuracy: 0.4724\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5096 - accuracy: 0.4483 - val_loss: 1.4255 - val_accuracy: 0.4798\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4950 - accuracy: 0.4538 - val_loss: 1.4017 - val_accuracy: 0.4998\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4869 - accuracy: 0.4574 - val_loss: 1.4290 - val_accuracy: 0.4840\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4756 - accuracy: 0.4594 - val_loss: 1.3966 - val_accuracy: 0.4978\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4633 - accuracy: 0.4688 - val_loss: 1.3864 - val_accuracy: 0.5006\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4536 - accuracy: 0.4719 - val_loss: 1.3889 - val_accuracy: 0.4994\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4434 - accuracy: 0.4729 - val_loss: 1.3946 - val_accuracy: 0.4944\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4352 - accuracy: 0.4804 - val_loss: 1.4024 - val_accuracy: 0.4960\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4304 - accuracy: 0.4802 - val_loss: 1.3412 - val_accuracy: 0.5146\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4239 - accuracy: 0.4833 - val_loss: 1.3812 - val_accuracy: 0.4990\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4129 - accuracy: 0.4869 - val_loss: 1.3558 - val_accuracy: 0.5142\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4130 - accuracy: 0.4900 - val_loss: 1.3420 - val_accuracy: 0.5196\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4024 - accuracy: 0.4932 - val_loss: 1.3427 - val_accuracy: 0.5202\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.3998 - accuracy: 0.4921 - val_loss: 1.3458 - val_accuracy: 0.5178\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3983 - accuracy: 0.4945 - val_loss: 1.3653 - val_accuracy: 0.5128\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3918 - accuracy: 0.4973 - val_loss: 1.3366 - val_accuracy: 0.5156\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3874 - accuracy: 0.4986 - val_loss: 1.3575 - val_accuracy: 0.5078\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3861 - accuracy: 0.4975 - val_loss: 1.3589 - val_accuracy: 0.5138\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3843 - accuracy: 0.5010 - val_loss: 1.3415 - val_accuracy: 0.5240\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3768 - accuracy: 0.5035 - val_loss: 1.3578 - val_accuracy: 0.5098\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3745 - accuracy: 0.5035 - val_loss: 1.4087 - val_accuracy: 0.5034\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3650 - accuracy: 0.5029 - val_loss: 1.3490 - val_accuracy: 0.5182\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3650 - accuracy: 0.5071 - val_loss: 1.3807 - val_accuracy: 0.5116\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.3630 - accuracy: 0.5090 - val_loss: 1.3647 - val_accuracy: 0.5104\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3626 - accuracy: 0.5076 - val_loss: 1.3528 - val_accuracy: 0.5166\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3624 - accuracy: 0.5084 - val_loss: 1.3671 - val_accuracy: 0.5144\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3536 - accuracy: 0.5119 - val_loss: 1.3436 - val_accuracy: 0.5262\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3513 - accuracy: 0.5136 - val_loss: 1.3424 - val_accuracy: 0.5172\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3510 - accuracy: 0.5122 - val_loss: 1.3454 - val_accuracy: 0.5210\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3479 - accuracy: 0.5134 - val_loss: 1.3504 - val_accuracy: 0.5194\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3454 - accuracy: 0.5135 - val_loss: 1.3487 - val_accuracy: 0.5202\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3413 - accuracy: 0.5147 - val_loss: 1.3396 - val_accuracy: 0.5256\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3344 - accuracy: 0.5183 - val_loss: 1.3425 - val_accuracy: 0.5204\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3417 - accuracy: 0.5184 - val_loss: 1.3447 - val_accuracy: 0.5214\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3360 - accuracy: 0.5167 - val_loss: 1.3690 - val_accuracy: 0.5208\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3339 - accuracy: 0.5180 - val_loss: 1.3604 - val_accuracy: 0.5136\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3306 - accuracy: 0.5188 - val_loss: 1.3376 - val_accuracy: 0.5266\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3229 - accuracy: 0.5226 - val_loss: 1.3357 - val_accuracy: 0.5170\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3302 - accuracy: 0.5222 - val_loss: 1.3407 - val_accuracy: 0.5204\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3293 - accuracy: 0.5193 - val_loss: 1.3412 - val_accuracy: 0.5126\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3267 - accuracy: 0.5223 - val_loss: 1.3407 - val_accuracy: 0.5164\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3281 - accuracy: 0.5211 - val_loss: 1.3357 - val_accuracy: 0.5224\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3198 - accuracy: 0.5246 - val_loss: 1.3375 - val_accuracy: 0.5232\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3223 - accuracy: 0.5222 - val_loss: 1.3610 - val_accuracy: 0.5136\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3183 - accuracy: 0.5269 - val_loss: 1.3385 - val_accuracy: 0.5270\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3136 - accuracy: 0.5269 - val_loss: 1.3273 - val_accuracy: 0.5308\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3097 - accuracy: 0.5306 - val_loss: 1.3371 - val_accuracy: 0.5286\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3150 - accuracy: 0.5278 - val_loss: 1.3264 - val_accuracy: 0.5306\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3119 - accuracy: 0.5287 - val_loss: 1.3186 - val_accuracy: 0.5312\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3103 - accuracy: 0.5268 - val_loss: 1.3314 - val_accuracy: 0.5358\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3071 - accuracy: 0.5318 - val_loss: 1.3494 - val_accuracy: 0.5158\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3074 - accuracy: 0.5316 - val_loss: 1.3433 - val_accuracy: 0.5260\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3075 - accuracy: 0.5293 - val_loss: 1.3554 - val_accuracy: 0.5194\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3052 - accuracy: 0.5315 - val_loss: 1.3196 - val_accuracy: 0.5394\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3001 - accuracy: 0.5335 - val_loss: 1.3563 - val_accuracy: 0.5180\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3014 - accuracy: 0.5304 - val_loss: 1.3460 - val_accuracy: 0.5302\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2973 - accuracy: 0.5332 - val_loss: 1.3373 - val_accuracy: 0.5224\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2954 - accuracy: 0.5341 - val_loss: 1.3483 - val_accuracy: 0.5190\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2992 - accuracy: 0.5317 - val_loss: 1.3804 - val_accuracy: 0.5106\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3020 - accuracy: 0.5293 - val_loss: 1.3631 - val_accuracy: 0.5198\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2921 - accuracy: 0.5388 - val_loss: 1.3310 - val_accuracy: 0.5324\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2920 - accuracy: 0.5371 - val_loss: 1.3400 - val_accuracy: 0.5254\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2888 - accuracy: 0.5383 - val_loss: 1.3290 - val_accuracy: 0.5296\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2879 - accuracy: 0.5361 - val_loss: 1.3379 - val_accuracy: 0.5170\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2860 - accuracy: 0.5377 - val_loss: 1.3208 - val_accuracy: 0.5302\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2823 - accuracy: 0.5414 - val_loss: 1.3342 - val_accuracy: 0.5324\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2853 - accuracy: 0.5416 - val_loss: 1.3287 - val_accuracy: 0.5346\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2852 - accuracy: 0.5392 - val_loss: 1.3361 - val_accuracy: 0.5238\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2791 - accuracy: 0.5388 - val_loss: 1.3341 - val_accuracy: 0.5260\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2886 - accuracy: 0.5424 - val_loss: 1.3234 - val_accuracy: 0.5336\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2854 - accuracy: 0.5400 - val_loss: 1.3263 - val_accuracy: 0.5224\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2821 - accuracy: 0.5396 - val_loss: 1.3663 - val_accuracy: 0.5258\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2809 - accuracy: 0.5402 - val_loss: 1.3361 - val_accuracy: 0.5388\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2815 - accuracy: 0.5396 - val_loss: 1.3326 - val_accuracy: 0.5290\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2697 - accuracy: 0.5422 - val_loss: 1.3275 - val_accuracy: 0.5318\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2766 - accuracy: 0.5439 - val_loss: 1.3533 - val_accuracy: 0.5270\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2689 - accuracy: 0.5462 - val_loss: 1.3284 - val_accuracy: 0.5306\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2776 - accuracy: 0.5417 - val_loss: 1.3223 - val_accuracy: 0.5340\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2731 - accuracy: 0.5441 - val_loss: 1.3378 - val_accuracy: 0.5248\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2704 - accuracy: 0.5468 - val_loss: 1.3417 - val_accuracy: 0.5202\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2722 - accuracy: 0.5451 - val_loss: 1.3399 - val_accuracy: 0.5220\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2673 - accuracy: 0.5459 - val_loss: 1.3359 - val_accuracy: 0.5246\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2680 - accuracy: 0.5435 - val_loss: 1.3521 - val_accuracy: 0.5232\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2630 - accuracy: 0.5468 - val_loss: 1.3375 - val_accuracy: 0.5242\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2664 - accuracy: 0.5451 - val_loss: 1.3276 - val_accuracy: 0.5234\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2663 - accuracy: 0.5456 - val_loss: 1.3388 - val_accuracy: 0.5234\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2615 - accuracy: 0.5491 - val_loss: 1.3380 - val_accuracy: 0.5248\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2553 - accuracy: 0.5490 - val_loss: 1.3315 - val_accuracy: 0.5302\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2605 - accuracy: 0.5476 - val_loss: 1.3268 - val_accuracy: 0.5304\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2664 - accuracy: 0.5480 - val_loss: 1.3338 - val_accuracy: 0.5230\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2623 - accuracy: 0.5504 - val_loss: 1.3638 - val_accuracy: 0.5182\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2665 - accuracy: 0.5480 - val_loss: 1.3363 - val_accuracy: 0.5312\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2615 - accuracy: 0.5482 - val_loss: 1.3286 - val_accuracy: 0.5318\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2617 - accuracy: 0.5490 - val_loss: 1.3762 - val_accuracy: 0.5156\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2624 - accuracy: 0.5490 - val_loss: 1.3632 - val_accuracy: 0.5186\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2538 - accuracy: 0.5500 - val_loss: 1.3237 - val_accuracy: 0.5244\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2535 - accuracy: 0.5512 - val_loss: 1.3536 - val_accuracy: 0.5182\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2579 - accuracy: 0.5494 - val_loss: 1.3372 - val_accuracy: 0.5250\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2569 - accuracy: 0.5508 - val_loss: 1.3228 - val_accuracy: 0.5206\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2535 - accuracy: 0.5508 - val_loss: 1.3561 - val_accuracy: 0.5194\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2565 - accuracy: 0.5500 - val_loss: 1.3340 - val_accuracy: 0.5226\n",
      "Epoch 111/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2591 - accuracy: 0.5486 - val_loss: 1.3322 - val_accuracy: 0.5172\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2515 - accuracy: 0.5504 - val_loss: 1.3243 - val_accuracy: 0.5178\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2511 - accuracy: 0.5544 - val_loss: 1.3570 - val_accuracy: 0.5246\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2517 - accuracy: 0.5512 - val_loss: 1.3379 - val_accuracy: 0.5132\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2534 - accuracy: 0.5514 - val_loss: 1.3305 - val_accuracy: 0.5286\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2482 - accuracy: 0.5528 - val_loss: 1.3700 - val_accuracy: 0.5178\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2503 - accuracy: 0.5527 - val_loss: 1.3417 - val_accuracy: 0.5318\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2540 - accuracy: 0.5522 - val_loss: 1.3534 - val_accuracy: 0.5202\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2441 - accuracy: 0.5559 - val_loss: 1.3357 - val_accuracy: 0.5182\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2496 - accuracy: 0.5555 - val_loss: 1.3293 - val_accuracy: 0.5244\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2451 - accuracy: 0.5558 - val_loss: 1.3361 - val_accuracy: 0.5194\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2436 - accuracy: 0.5560 - val_loss: 1.3237 - val_accuracy: 0.5314\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2479 - accuracy: 0.5542 - val_loss: 1.3386 - val_accuracy: 0.5262\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2500 - accuracy: 0.5537 - val_loss: 1.3377 - val_accuracy: 0.5256\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2449 - accuracy: 0.5555 - val_loss: 1.3467 - val_accuracy: 0.5216\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2395 - accuracy: 0.5582 - val_loss: 1.3220 - val_accuracy: 0.5302\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2447 - accuracy: 0.5533 - val_loss: 1.3294 - val_accuracy: 0.5242\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2464 - accuracy: 0.5564 - val_loss: 1.3336 - val_accuracy: 0.5252\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2354 - accuracy: 0.5590 - val_loss: 1.3322 - val_accuracy: 0.5102\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2451 - accuracy: 0.5565 - val_loss: 1.3451 - val_accuracy: 0.5230\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2388 - accuracy: 0.5576 - val_loss: 1.3345 - val_accuracy: 0.5214\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2378 - accuracy: 0.5563 - val_loss: 1.3421 - val_accuracy: 0.5180\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2344 - accuracy: 0.5588 - val_loss: 1.3156 - val_accuracy: 0.5318\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2409 - accuracy: 0.5561 - val_loss: 1.3317 - val_accuracy: 0.5244\n",
      "Epoch 135/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2382 - accuracy: 0.5544 - val_loss: 1.3332 - val_accuracy: 0.5266\n",
      "Epoch 136/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2435 - accuracy: 0.5569 - val_loss: 1.3466 - val_accuracy: 0.5178\n",
      "Epoch 137/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2399 - accuracy: 0.5561 - val_loss: 1.3312 - val_accuracy: 0.5296\n",
      "Epoch 138/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2441 - accuracy: 0.5561 - val_loss: 1.3374 - val_accuracy: 0.5260\n",
      "Epoch 139/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2348 - accuracy: 0.5588 - val_loss: 1.3454 - val_accuracy: 0.5240\n",
      "Epoch 140/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2375 - accuracy: 0.5565 - val_loss: 1.3540 - val_accuracy: 0.5184\n",
      "Epoch 141/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2413 - accuracy: 0.5566 - val_loss: 1.3265 - val_accuracy: 0.5282\n",
      "Epoch 142/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2334 - accuracy: 0.5613 - val_loss: 1.3375 - val_accuracy: 0.5264\n",
      "Epoch 143/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2324 - accuracy: 0.5605 - val_loss: 1.3342 - val_accuracy: 0.5188\n",
      "Epoch 144/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2317 - accuracy: 0.5613 - val_loss: 1.3493 - val_accuracy: 0.5148\n",
      "Epoch 145/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2413 - accuracy: 0.5545 - val_loss: 1.3292 - val_accuracy: 0.5222\n",
      "Epoch 146/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2384 - accuracy: 0.5564 - val_loss: 1.3229 - val_accuracy: 0.5194\n",
      "Epoch 147/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2346 - accuracy: 0.5592 - val_loss: 1.3390 - val_accuracy: 0.5132\n",
      "Epoch 148/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2348 - accuracy: 0.5607 - val_loss: 1.3370 - val_accuracy: 0.5252\n",
      "Epoch 149/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2405 - accuracy: 0.5570 - val_loss: 1.3339 - val_accuracy: 0.5222\n",
      "Epoch 150/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2374 - accuracy: 0.5572 - val_loss: 1.3752 - val_accuracy: 0.5198\n",
      "Epoch 151/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2316 - accuracy: 0.5600 - val_loss: 1.3304 - val_accuracy: 0.5288\n",
      "Epoch 152/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2292 - accuracy: 0.5612 - val_loss: 1.3379 - val_accuracy: 0.5214\n",
      "Epoch 153/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2293 - accuracy: 0.5642 - val_loss: 1.3155 - val_accuracy: 0.5294\n",
      "Epoch 154/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2310 - accuracy: 0.5629 - val_loss: 1.3506 - val_accuracy: 0.5214\n",
      "Epoch 155/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2340 - accuracy: 0.5584 - val_loss: 1.3418 - val_accuracy: 0.5240\n",
      "Epoch 156/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2292 - accuracy: 0.5619 - val_loss: 1.3421 - val_accuracy: 0.5180\n",
      "Epoch 157/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2325 - accuracy: 0.5589 - val_loss: 1.3256 - val_accuracy: 0.5214\n",
      "Epoch 158/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2309 - accuracy: 0.5615 - val_loss: 1.3454 - val_accuracy: 0.5200\n",
      "Epoch 159/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2305 - accuracy: 0.5626 - val_loss: 1.3526 - val_accuracy: 0.5138\n",
      "Epoch 160/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2269 - accuracy: 0.5609 - val_loss: 1.3322 - val_accuracy: 0.5250\n",
      "Epoch 161/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2288 - accuracy: 0.5610 - val_loss: 1.3567 - val_accuracy: 0.5128\n",
      "Epoch 162/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2320 - accuracy: 0.5623 - val_loss: 1.3355 - val_accuracy: 0.5186\n",
      "Epoch 163/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2300 - accuracy: 0.5584 - val_loss: 1.3360 - val_accuracy: 0.5188\n",
      "Epoch 164/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2300 - accuracy: 0.5624 - val_loss: 1.3227 - val_accuracy: 0.5298\n",
      "Epoch 165/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2232 - accuracy: 0.5641 - val_loss: 1.3340 - val_accuracy: 0.5224\n",
      "Epoch 166/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2245 - accuracy: 0.5639 - val_loss: 1.3258 - val_accuracy: 0.5258\n",
      "Epoch 167/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2268 - accuracy: 0.5622 - val_loss: 1.3349 - val_accuracy: 0.5272\n",
      "Epoch 168/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2218 - accuracy: 0.5651 - val_loss: 1.3334 - val_accuracy: 0.5224\n",
      "Epoch 169/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2261 - accuracy: 0.5650 - val_loss: 1.3582 - val_accuracy: 0.5138\n",
      "Epoch 170/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2247 - accuracy: 0.5636 - val_loss: 1.3337 - val_accuracy: 0.5168\n",
      "Epoch 171/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2261 - accuracy: 0.5623 - val_loss: 1.3350 - val_accuracy: 0.5192\n",
      "Epoch 172/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2255 - accuracy: 0.5626 - val_loss: 1.3334 - val_accuracy: 0.5164\n",
      "Epoch 173/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2222 - accuracy: 0.5642 - val_loss: 1.3312 - val_accuracy: 0.5314\n",
      "Epoch 174/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2288 - accuracy: 0.5627 - val_loss: 1.3379 - val_accuracy: 0.5188\n",
      "Epoch 175/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2242 - accuracy: 0.5637 - val_loss: 1.3443 - val_accuracy: 0.5244\n",
      "Epoch 176/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2189 - accuracy: 0.5658 - val_loss: 1.3346 - val_accuracy: 0.5200\n",
      "Epoch 177/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2138 - accuracy: 0.5671 - val_loss: 1.3325 - val_accuracy: 0.5218\n",
      "Epoch 178/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2230 - accuracy: 0.5643 - val_loss: 1.3373 - val_accuracy: 0.5148\n",
      "Epoch 179/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2260 - accuracy: 0.5635 - val_loss: 1.3389 - val_accuracy: 0.5260\n",
      "Epoch 180/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2185 - accuracy: 0.5658 - val_loss: 1.3266 - val_accuracy: 0.5226\n",
      "Epoch 181/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2182 - accuracy: 0.5630 - val_loss: 1.3280 - val_accuracy: 0.5184\n",
      "Epoch 182/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2127 - accuracy: 0.5696 - val_loss: 1.3373 - val_accuracy: 0.5226\n",
      "Epoch 183/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2227 - accuracy: 0.5637 - val_loss: 1.3739 - val_accuracy: 0.5118\n",
      "Epoch 184/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2175 - accuracy: 0.5673 - val_loss: 1.3173 - val_accuracy: 0.5264\n",
      "Epoch 185/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2172 - accuracy: 0.5672 - val_loss: 1.3324 - val_accuracy: 0.5162\n",
      "Epoch 186/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2176 - accuracy: 0.5661 - val_loss: 1.3390 - val_accuracy: 0.5266\n",
      "Epoch 187/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2115 - accuracy: 0.5658 - val_loss: 1.3342 - val_accuracy: 0.5256\n",
      "Epoch 188/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2149 - accuracy: 0.5643 - val_loss: 1.3273 - val_accuracy: 0.5290\n",
      "Epoch 189/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2209 - accuracy: 0.5665 - val_loss: 1.3342 - val_accuracy: 0.5242\n",
      "Epoch 190/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2213 - accuracy: 0.5669 - val_loss: 1.3545 - val_accuracy: 0.5176\n",
      "Epoch 191/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2170 - accuracy: 0.5671 - val_loss: 1.3314 - val_accuracy: 0.5310\n",
      "Epoch 192/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2173 - accuracy: 0.5623 - val_loss: 1.3433 - val_accuracy: 0.5238\n",
      "Epoch 193/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2216 - accuracy: 0.5632 - val_loss: 1.3314 - val_accuracy: 0.5282\n",
      "Epoch 194/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2140 - accuracy: 0.5666 - val_loss: 1.3294 - val_accuracy: 0.5280\n",
      "Epoch 195/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2097 - accuracy: 0.5688 - val_loss: 1.3447 - val_accuracy: 0.5184\n",
      "Epoch 196/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2143 - accuracy: 0.5657 - val_loss: 1.3366 - val_accuracy: 0.5210\n",
      "Epoch 197/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2211 - accuracy: 0.5650 - val_loss: 1.3420 - val_accuracy: 0.5252\n",
      "Epoch 198/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2160 - accuracy: 0.5676 - val_loss: 1.3237 - val_accuracy: 0.5236\n",
      "Epoch 199/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2094 - accuracy: 0.5702 - val_loss: 1.3454 - val_accuracy: 0.5272\n",
      "Epoch 200/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2068 - accuracy: 0.5708 - val_loss: 1.3446 - val_accuracy: 0.5216\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1565.2753 - accuracy: 0.2381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1565.2752685546875, 0.23810000717639923]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "num_epochs = 200 \n",
    "kernel_size = 5 # мы будем использовать ядра 3x3 повсюду\n",
    "pool_size = 2 # мы будем использовать объединение 2х2 повсюду\n",
    "conv_depth_1 = 32 # первоначально у нас будет 32 ядра на слой преобразования\n",
    "conv_depth_2 = 64 # переключение на 64 после первого уровня объединения\n",
    "drop_prob_1 = 0.25 # выбывает после объединения с вероятностью 0,25\n",
    "drop_prob_2 = 0.5 # выпадают в плотном слое с вероятностью 0,5\n",
    "hidden_size = 512 # в плотном слое будет 512 нейронов\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # извлечение данных CIFAR-10\n",
    "num_train, depth, height, width = X_train.shape # в CIFAR-10 содержится 50000 обучающих примеров\n",
    "num_test = X_test.shape[0] # в CIFAR-10 содержится 10000 тестовых примеров\n",
    "num_classes = np.unique(y_train).shape[0] # существует 10 классов изображений\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "X_test /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # кодирование тренировачных данных\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # кодирование тестировочных данных\n",
    "\n",
    "\n",
    "inp = Input(shape=(depth, height, width)) # N.B. глубина занимает первое место в Керасе\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(inp) #устарело\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size),padding='same')(conv_4) # padding='same' входное изображение должно иметь нулевое заполнение, чтобы вывод в свертке не отличался по размеру от ввода. \n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "#Теперь выровняйте до 1D, примените Плотный -> ReLU (с выпадением) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "model = Model(inputs=inp, outputs=out) # Чтобы определить модель, просто укажите ее входные и выходные слои\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1) # \n",
    "model.evaluate(X_test, Y_test, verbose=1) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eef95b89b117c20879678c0826dbc0e65d56cf8ab983c95002ee10fa11e0c03f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
